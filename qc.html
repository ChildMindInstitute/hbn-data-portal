
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Data Quality &mdash; Child Mind Institute Healthy Brain Network: Scientific Data Portal</title>
    
    <link rel="stylesheet" href="_static/nature.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     '',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="Child Mind Institute Healthy Brain Network: Scientific Data Portal" href="index.html" />
  </head>
  <body>
  
    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="data-quality">
<h1>Data Quality<a class="headerlink" href="#data-quality" title="Permalink to this headline">¶</a></h1>
<p>Consistent with policies established through our prior data generation and sharing initiatives (i.e., FCP/INDI (Mennes et al. 2013); NKI-Rockland Sample (Nooner et al. 2012)), all imaging datasets collected through the HBN are being made available to users - regardless of data quality. This decision is justified by a lack of consensus in the imaging community on what constitutes “good” or “poor” quality data. Also, “lower quality” datasets can facilitate the development of artifact correction techniques and of evaluating the impact of such real-world confounds on reliability and reproducibility. Given the range of clinical presentations in the HBN, the inclusion of datasets of varying qualities creates a unique opportunity to test for associations with participant-related variables of interest beyond age and hyperactivity (e.g., anxiety, autistic traits). </p>

<div class="section" id="mri">
<h2>MRI Data<a class="headerlink" href="#mri" title="Permalink to this headline">¶</a></h2>
<p>Consistent with recent major FCP/INDI data releases (i.e., the Consortium for Reliability and Reproducibility [CoRR](Zuo et al. 2014), Autism Brain Imaging Data Exchange 2 [ABIDE 2](Di Martino et al. 2017)), we made use of the Preprocessed Connectome Project Quality Assurance Protocol (QAP; Shehzad et al., 2013) to assess data quality for core MRI data modalities (i.e., functional MRI, morphometry MRI and diffusion MRI). The QAP includes a broad range of quantitative measures that have been proposed for assessing image data quality (see table below for list of measures and their definitions, adapted from (Di Martino et al. 2017)).</p>
<img alt="QAP Measures" src="_images/_qc/neuro_qap_measures.png" style="display: block; margin: auto; max-width: 800px;"/>
<p>Given commonly cited concerns about head motion during MRI scans, particularly during resting state fMRI scans, age-related differences in motion were examined. Head motion was quantified using frame-wise displacement (FD), which is calculated using root mean square deviation(Jenkinson et al. 2002). Mean FD is commonly used to evaluate the impact of movement on a dataset (Power et al. 2015), but it cannot distinguish between occasional large movements and frequent smaller movements, the effects of the former being likely easier to fix using scrubbing or an volume censoring methods. Consistent with this concern, the following figure demonstrates a nonlinear relationship between mean FD and median FD, with the latter providing a better indication of the amount of the data that can be retained after movement correction (e.g., volume censoring).</p>
<img alt="Mean FD" src="_images/_qc/neuro_fd.png" style="display: block; margin: auto; max-width: 1000px;"/>
<p>Consistent with prior work (Power et al. 2012), both sites (the 1.5 Tesla mobile scanner in Staten Island and the 3 T fixed scanner at Rutgers University) exhibited negative associations between age and head motion for all functional scan types, with children between ages 5 and 8 exhibiting the greatest levels of movement. Median FD tended to be higher during the second half (5 minutes) of the resting state scan than during the first half; this observation resulted in our decision to split the scan into two 5-minute scans<!-- starting with participant #-->. As predicted by recent work highlighting the advantages of naturalistic viewing to minimize head motion, we found that head motion was significantly reduced during each of the movie-watching scan sessions (“Despicable Me,” “The Present”) relative to rest.</p>
<p>Beyond the examination of temporal characteristics of the HBN data, we also applied the structural measures included in the PCP QA to each of the core data types collected (functional, diffusion, morphometry). See figure below for a subset of these measures. More information about the quality control process used for HBN MRI data can be found at the <a href="http://preprocessed-connectomes-project.org/quality-assessment-protocol/">PCP Assurance Protocol webpage</a>.</p>
<img alt="Mean FD" src="_images/_qc/neuro_qap.png" style="display: block; margin: auto; max-width: 800px;"/>
</div>
<div class="section" id="head-motion">
<h2>Handling Head Motion in MRI Data<a class="headerlink" href="#head-motion" title="Permalink to this headline">¶</a></h2>
<p>Head motion presents an unavoidable challenge for developmental and clinical imaging, regardless of MRI modality (fMRI, dMRI, sMRI). Arguably, the most basic strategy for handling motion, short of applying an uncomfortable motion-restricting apparatus, is limiting analyses to high-quality datasets. The Brain Genomic Superstruct data release is an excellent example of the utility of large-scale datasets in supporting such a strategy, as 1570 datasets were selected for analyses from a pool of 3000 individuals following rigorous quality control (Holmes et al. 2015). A limitation of this strategy for psychiatric data is that many phenotypes of interest are inherently more prone to head motion (e.g., children under 9, those with Attention-Deficit/Hyperactivity Disorder), especially those with higher levels of symptomatology. Compounding the downsides of discarding data are the increased costs associated with the recruitment and phenotyping of clinical populations.</p>
<p>For functional MRI, an alternative strategy is to statistically correct the data for movement-induced intensity fluctuations, or remove offending time frames altogether (Power et al. 2015). This can be accomplished by a number of means, ranging from regressing a model of movement from the data (e.g., spike regression (Satterthwaite et al. 2013)), removing the contributions of motion-related spatial patterns from the data (AROMA (Pruim et al. 2015)), attenuating motion spikes using a squashing function, removing offending frames, zeroing out offending frames, or deleting offending frames followed by interpolation. More generalized correction approaches, such as global signal regression and forms of white matter and cerebrospinal fluid regression (e.g., tCompCor, aCompCor (Behzadi et al. 2007; Chai et al. 2012)) can also help to account for motion artifacts. While there is no consensus approach to date, there is a growing literature focused on providing benchmark evaluations of these approaches, as well as their relative merits and weaknesses (e.g., see (Ciric et al. 2017)(Yan et al. 2013)), that can be used to help select among these corrections.</p>
<p>More broadly, group-level statistical corrections can be used to account for the contributions of motion-related artifacts to associations revealed through data analysis (Satterthwaite et al. 2013). In the case of functional MRI, this can be accomplished by including motion parameters as a statistical covariate at the group level. Given the trait nature of head motion (Zuo et al. 2014), some have advocated for using fMRI-derived motion parameters in structural analysis as well. Alternatively, accounting for full-brain differences in measures of interest at the group-level has been shown to be a potentially valuable approach to minimizing the deleterious effects of motion, particularly for fMRI (Yan et al. 2013).</p>
<p>It is our hope that the breadth of the Healthy Brain Network dataset will provide a practical perspective of the challenges of motion for various domains of illness and help to stimulate continued development and testing of novel correction strategies.</p>
</div>
<div class="section" id="eeg">
<h2>EEG Data<a class="headerlink" href="#eeg" title="Permalink to this headline">¶</a></h2>
<p>For each of the EEG acquisitions included, the figure below depicts the number of channels rejected based on the data distribution and variance of channels (threshold: > 3 standard deviations), as implemented in EEGLAB's pop_rejchan.m function (Delorme and Makeig 2004).</p>
<img alt="Number of EEG Channels Rejected" src="_images/_qc/neuro_eeg.png" style="display: block; margin: auto; max-width: 800px;"/>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
            <p class="logo"><a href="index.html">
              <img class="logo" src="_static/HBN_logo_4color.jpg" style="width: 240px; display: block; margin: auto;" alt="Logo"/>
            </a></p>
<h3></h3>
<ul>
<li class="toctree-l1"><a class="reference internal" href="index.html">Home</a></li>
<li class="toctree-l1"><a class="reference external" href="https://www.nature.com/articles/sdata2017181">Link to Manuscript</a></li>
<li class="toctree-l1"><a class="reference internal" href="project_plan.html">Project Plan</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_timeline.html">Data Release Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="updates.html">Fixes and Updates</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="updates.html#protocol-timeline">Protocol Timeline</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="inclusion.html">Inclusion/Exclusion Criteria</a></li>
<li class="toctree-l1"><a class="reference internal" href="recruit.html">Recruitment</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="recruit.html#community-advertising">Community Advertisements</a></li>
<li class="toctree-l2"><a class="reference internal" href="recruit.html#partnerships">Partnerships</a></li>
<li class="toctree-l2"><a class="reference internal" href="recruit.html#branding">Branding</a></li>
</ul><li class="toctree-l1"><a class="reference internal" href="sched.html">Participant Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="eeg_protocol.html">EEG Protocol</a></li>
<li class="toctree-l1"><a class="reference internal" href="mri_protocol.html">MRI Protocol</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="mri_protocol.html#mri-scan-parameters">MRI Scan Parameters</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="assessments.html">Assessments</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="assessments.html#protocol-summary">Protocol Summary</a></li>
<li class="toctree-l2"><a class="reference internal" href="assessments.html#diagnostic-tools">HBN Diagnostic Tools</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="protocol_timeline.html">Protocol Timeline</a></li>
<li class="toctree-l1"><a class="reference internal" href="behavior.html">Behavior Monitoring Technologies</a></li>
<li class="toctree-l1"><a class="reference internal" href="demo.html">Sample Characteristics</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="demo.html#age-and-sex-distributions">Age and Sex Distribution</a></li>
<li class="toctree-l2"><a class="reference internal" href="demo.html#DSM-5-diagnoses">DSM-5 Diagnoses</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="sharing_neuro.html">Neuroimaging Data Access</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="sharing_neuro.html#direct-downloads">Direct Downloads</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharing_neuro.html#data-license">Data License</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="sharing_phenotypic.html">Phenotypic Data Access</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="sharing_phenotypic.html#participant-identifiers">Participant Identifiers</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharing_phenotypic.html#data-usage-agreement">Data Usage Agreement</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharing_phenotypic.html#coins-data-exchange">COINS Data Exchange</a></li>
<li class="toctree-l2"><a class="reference internal" href="sharing_phenotypic.html#loris">LORIS</a></li>
</ul>
<li class="toctree-l1 current"><a class="current reference internal" href="qc.html">Data Quality</a></li><ul>
<li class="toctree-l2"><a class="reference internal" href="qc.html#mri">MRI Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="qc.html#head-motion">Handling Head Motion in MRI Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="qc.html#eeg">EEG Data</a></li>
</ul>
<li class="toctree-l1"><a class="reference internal" href="citation.html">Citation of Data Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="support.html">Support</a></li>
</ul>

        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
        &copy; Copyright 2018, INDI.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.1.3.
    </div>
  </body>
</html>